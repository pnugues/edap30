{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Toy Implementation of CBOW\n",
    "\n",
    "Adapted from _Efficient estimation of word representations in vector space_ by Mikolov et al., 2013.\n",
    "\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import os\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "import collections\n",
    "from math import log\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding size and context size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_dim = 50\n",
    "w_size = 2\n",
    "c_size = w_size * 2 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'homer'  # 'homer' dickens' 'selma' 'big'\n",
    "colab = False  # On my machine or on colab\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    BASE_PATH = '/content/drive/My Drive/Colab Notebooks/'\n",
    "else:\n",
    "    BASE_PATH = '/Users/pierre/Documents/Cours/EDAN20/corpus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the files from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir, suffix):\n",
    "    \"\"\"\n",
    "    Returns all the files in a folder ending with suffix\n",
    "    :param dir:\n",
    "    :param suffix:\n",
    "    :return: the list of file names\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith(suffix):\n",
    "            files.append(file)\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_corpus(path):\n",
    "    files = get_files(path, 'txt')\n",
    "    files = [path + file for file in files]\n",
    "    print(files)\n",
    "    text = ''\n",
    "    for file in files:\n",
    "        text += open(file).read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if corpus == 'homer':\n",
    "    # text = 'Sing, O goddess, the anger of Achilles son of Peleus'.lower()\n",
    "    text1 = open(BASE_PATH + 'Homer/iliad.txt',\n",
    "                 encoding='utf-8').read().lower()\n",
    "    text2 = open(BASE_PATH + 'Homer/odyssey.txt',\n",
    "                 encoding='utf-8').read().lower()\n",
    "    text = text1 + text2\n",
    "    test_words = ['he', 'she', 'ulysses', 'penelope', 'achaeans', 'trojans',\n",
    "                  'achilles', 'sea', 'helen', 'ship', 'her', 'fight']\n",
    "if corpus == 'dickens':\n",
    "    path = BASE_PATH + 'Dickens/'\n",
    "    text = load_corpus(path)\n",
    "    test_words = ['he', 'she', 'paris', 'london', 'table', 'rare', 'monday', \n",
    "                  'sunday', 'man', 'woman', 'king', 'queen', 'boy',\n",
    "                  'girl']\n",
    "elif corpus == 'selma':\n",
    "    path = BASE_PATH + 'Selma/'\n",
    "    text = load_corpus(path)\n",
    "    test_words = ['han', 'hon', 'att', 'bord', 'bordet', 'måndag', 'söndag', \n",
    "                  'man', 'kvinna', 'kung', 'drottning',\n",
    "                  'pojke', 'flicka']\n",
    "elif corpus == 'big':\n",
    "    path = BASE_PATH + 'Dickens/'\n",
    "    text = load_corpus(path)\n",
    "    path = BASE_PATH + 'Norvig/'\n",
    "    text += load_corpus(path)\n",
    "    test_words = ['he', 'she', 'paris', 'london', 'table', 'rare', 'monday', \n",
    "                  'sunday', 'man', 'woman', 'king', 'queen', 'boy',\n",
    "                  'girl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set all the text in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['book', 'i', 'sing', 'o', 'goddess']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.lower()\n",
    "words = re.findall('\\p{L}+', text)\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'abantes',\n",
       " 'abarbarea',\n",
       " 'abas',\n",
       " 'abate',\n",
       " 'abated',\n",
       " 'abetting',\n",
       " 'abhorred',\n",
       " 'abians',\n",
       " 'abide']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(words)))\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9768"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = dict(enumerate(vocab))\n",
    "word2idx = {v: k for k, v in idx2word.items()}\n",
    "# word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_idx = [word2idx[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Xy(words):\n",
    "    (X, y) = ([], [])\n",
    "    c_size = 2 * w_size + 1\n",
    "    for i in range(len(words) - c_size + 1):\n",
    "        X.append(words[i: i + w_size] +\n",
    "                       words[i + w_size + 1: i + c_size])\n",
    "        y.append(words[i + w_size])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_Xy(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sing', 'o', 'the', 'anger'],\n",
       " ['o', 'goddess', 'anger', 'of'],\n",
       " ['goddess', 'the', 'of', 'achilles']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goddess', 'the', 'anger']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_Xy(words_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([271502, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.LongTensor(X)\n",
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7663, 5691, 8548,  358],\n",
       "        [5691, 3697,  358, 5735],\n",
       "        [3697, 8548, 5735,   67]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3697, 8548,  358])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(9768, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.2197, -0.2524, -0.0096, -0.6269,  0.9489],\n",
       "                      [-0.4396, -0.2060, -0.4804,  0.8526,  0.4017],\n",
       "                      [ 0.7069,  0.9471, -1.4317,  1.1851, -1.1871],\n",
       "                      ...,\n",
       "                      [ 0.0973, -0.4191,  0.4433,  1.4194,  0.6204],\n",
       "                      [ 0.2059, -0.7927, -0.4884, -0.1608, -0.1177],\n",
       "                      [-2.0196, -0.9487,  0.5686,  0.0996, -1.1322]]))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2197, -0.2524, -0.0096, -0.6269,  0.9489],\n",
       "        [-0.4396, -0.2060, -0.4804,  0.8526,  0.4017],\n",
       "        [ 0.7069,  0.9471, -1.4317,  1.1851, -1.1871],\n",
       "        [ 1.6712,  2.5037, -0.4875,  0.1586, -0.6008],\n",
       "        [-2.4211, -0.2598, -0.2616, -1.4016, -0.3101]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6712,  2.5037, -0.4875,  0.1586, -0.6008],\n",
       "        [ 0.7069,  0.9471, -1.4317,  1.1851, -1.1871],\n",
       "        [-0.4396, -0.2060, -0.4804,  0.8526,  0.4017]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(torch.LongTensor([3, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4633,  0.4616, -0.2462,  0.6131,  0.8388],\n",
       "         [-0.9238, -0.1900, -0.3940, -0.2841, -2.0084],\n",
       "         [-0.7078,  0.1404, -0.1050, -0.7115,  1.3475],\n",
       "         [ 1.1688,  0.4074,  1.4692,  1.5402, -0.2261]],\n",
       "\n",
       "        [[-0.9238, -0.1900, -0.3940, -0.2841, -2.0084],\n",
       "         [ 0.6921,  1.0906, -1.3340,  1.8316, -1.5643],\n",
       "         [ 1.1688,  0.4074,  1.4692,  1.5402, -0.2261],\n",
       "         [-0.2756, -1.3336,  0.2185, -0.8684,  1.4908]],\n",
       "\n",
       "        [[ 0.6921,  1.0906, -1.3340,  1.8316, -1.5643],\n",
       "         [-0.7078,  0.1404, -0.1050, -0.7115,  1.3475],\n",
       "         [-0.2756, -1.3336,  0.2185, -0.8684,  1.4908],\n",
       "         [-0.7077,  0.7486, -1.2832, -0.0102,  1.3289]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(X[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(X[2:5]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4195e-04,  2.0484e-01,  1.8100e-01,  2.8941e-01, -1.2054e-02],\n",
       "        [ 1.6540e-01, -6.4217e-03, -1.0069e-02,  5.5484e-01, -5.7701e-01],\n",
       "        [-2.4975e-01,  1.6150e-01, -6.2593e-01,  6.0364e-02,  6.5072e-01]],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(X[2:5]).mean(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_bag = nn.EmbeddingBag(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_bag = nn.EmbeddingBag.from_pretrained(\n",
    "    embedding.state_dict()['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4195e-04,  2.0484e-01,  1.8100e-01,  2.8941e-01, -1.2054e-02],\n",
       "        [ 1.6540e-01, -6.4217e-03, -1.0069e-02,  5.5484e-01, -5.7701e-01],\n",
       "        [-2.4975e-01,  1.6150e-01, -6.2593e-01,  6.0364e-02,  6.5072e-01]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_bag(X[2:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_sim_vecs(u, E, N=10):\n",
    "    cos = nn.CosineSimilarity()\n",
    "    cos_sim = cos(u.unsqueeze(dim=0), E)\n",
    "    sorted_vectors = sorted(range(len(cos_sim)),\n",
    "                            key=lambda k: -cos_sim[k])\n",
    "    return sorted_vectors[1:N + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6160, 6333, 4156, 9394, 269, 5225, 8276, 6434, 8622, 8805]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_sim_vecs(embedding_bag.weight[0], embedding_bag.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_test_words(test_words, word2idx, model, N=10):\n",
    "    most_sim_words = {}\n",
    "    with torch.no_grad():\n",
    "        E = model[0].weight\n",
    "        for w in test_words:\n",
    "            most_sim_words[w] = most_sim_vecs(E[word2idx[w]], E, N)\n",
    "            most_sim_words[w] = list(map(idx2word.get, most_sim_words[w]))\n",
    "            print(w, most_sim_words[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): EmbeddingBag(9768, 50, mode='mean')\n",
       "  (1): Linear(in_features=50, out_features=9768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.EmbeddingBag(vocab_size, embedding_dim),\n",
    "    nn.Linear(embedding_dim, vocab_size))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0333, -0.1703, -0.2281,  ...,  0.0295,  0.3106,  0.1363],\n",
       "        [-0.2216, -0.1459, -0.4870,  ...,  0.2909,  0.3207, -0.3923],\n",
       "        [-0.0215,  0.4377,  0.0982,  ...,  0.0033,  0.0923,  0.1690],\n",
       "        [ 0.1256, -0.0816,  0.1194,  ...,  0.1172,  0.0826,  0.1682],\n",
       "        [-0.2369, -0.4697, -0.3122,  ...,  0.2402,  0.4668, -0.1937]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X[2:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class ModelCBOW(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.embedding = nn.Embedding.from_pretrained(embs.state_dict()['weight'])\\n        self.fc = nn.Linear(embedding_dim, vocab_size)\\n\\n    def forward(self, X):\\n        X = self.embedding(X)\\n        X = X.mean(dim=1)\\n        return self.fc(X)\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class ModelCBOW(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embs.state_dict()['weight'])\n",
    "        self.fc = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.embedding(X)\n",
    "        X = X.mean(dim=1)\n",
    "        return self.fc(X)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelCBOW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.0855, -0.8331, -1.2195,  ...,  1.0000, -1.0432, -0.5915],\n",
       "                      [-0.4350, -1.6720,  0.0238,  ...,  1.8459, -1.0771, -0.6815],\n",
       "                      [-1.5126,  2.7201, -1.1328,  ...,  0.2764,  2.2296,  1.9437],\n",
       "                      ...,\n",
       "                      [-0.5555,  1.1247,  0.6710,  ..., -0.4662, -0.0126, -1.3139],\n",
       "                      [ 2.1909,  0.8829,  0.5889,  ..., -0.4768, -0.6070,  0.9005],\n",
       "                      [ 0.2502,  1.9061,  1.2361,  ...,  0.0352,  0.5654,  0.9707]])),\n",
       "             ('1.weight',\n",
       "              tensor([[-0.0821,  0.1169,  0.0793,  ...,  0.0020, -0.0126,  0.0317],\n",
       "                      [ 0.0202,  0.0407, -0.0577,  ...,  0.0036, -0.0222,  0.0970],\n",
       "                      [ 0.0871,  0.0561,  0.0947,  ...,  0.1172,  0.0361, -0.0720],\n",
       "                      ...,\n",
       "                      [ 0.1151, -0.0881,  0.0428,  ...,  0.0082,  0.0687, -0.0011],\n",
       "                      [ 0.0824, -0.1305, -0.0797,  ...,  0.0420, -0.0458,  0.1240],\n",
       "                      [ 0.0750, -0.0184,  0.0638,  ...,  0.1272, -0.0110, -0.0150]])),\n",
       "             ('1.bias',\n",
       "              tensor([-0.0070, -0.1066,  0.0042,  ...,  0.0007, -0.0287, -0.0599]))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()    # cross entropy loss\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train validation loop to be able to call it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_loop():\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(10)):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        batch_cnt = 0\n",
    "        for X_batch, y_batch in train_dataloader:\n",
    "            y_batch_pred = model(X_batch)\n",
    "            loss = loss_fn(y_batch_pred, y_batch)\n",
    "            train_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_acc += torch.sum(y_batch ==\n",
    "                                    torch.argmax(y_batch_pred, dim=-1))/BATCH_SIZE\n",
    "            batch_cnt += 1\n",
    "        train_acc /= batch_cnt\n",
    "        train_acc_history += [train_acc]\n",
    "        train_loss /= batch_cnt\n",
    "        train_loss_history += [train_loss]\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_acc = 0\n",
    "            val_loss = 0\n",
    "            val_batch_cnt = 0\n",
    "            for X_batch, y_batch in val_dataloader:\n",
    "                y_batch_pred = model(X_batch)\n",
    "                loss = loss_fn(y_batch_pred, y_batch)\n",
    "                val_loss += loss.item()\n",
    "                val_acc += torch.sum(y_batch ==\n",
    "                                        torch.argmax(y_batch_pred, dim=-1))/BATCH_SIZE\n",
    "                val_batch_cnt += 1\n",
    "            val_acc /= val_batch_cnt\n",
    "            val_acc_history += [val_acc]\n",
    "            val_loss /= val_batch_cnt\n",
    "            val_loss_history += [val_loss]\n",
    "            sim_test_words(test_words, word2idx, model)\n",
    "    return train_loss_history, train_acc_history, val_loss_history, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(5)):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        batch_cnt = 0\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            y_batch_pred = model(X_batch)\n",
    "            loss = loss_fn(y_batch_pred, y_batch)\n",
    "            train_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_acc += torch.sum(y_batch ==\n",
    "                                    torch.argmax(y_batch_pred, dim=-1))/BATCH_SIZE\n",
    "            batch_cnt += 1\n",
    "        train_acc /= batch_cnt\n",
    "        train_acc_history += [train_acc]\n",
    "        train_loss /= batch_cnt\n",
    "        train_loss_history += [train_loss]\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            sim_test_words(test_words, word2idx, model)\n",
    "    return train_loss_history, train_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`VAL` should be set to true. The other choice is to study the influence of having a validation set on a small corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he ['she', 'they', 'achilles', 'violet', 'loath', 'i', 'twice', 'agrius', 'agamemnon', 'warmth']\n",
      "she ['he', 'ulysses', 'they', 'boeotian', 'pelagon', 'grassed', 'nausicaa', 'mounting', 'severe', 'heretofore']\n",
      "ulysses ['she', 'telemachus', 'ordered', 'approve', 'disgraced', 'achilles', 'lowest', 'agamemnon', 'bloodshed', 'behaving']\n",
      "penelope ['circe', 'direct', 'chirrup', 'tracks', 'beauty', 'eyesight', 'behave', 'chide', 'storms', 'oblige']\n",
      "achaeans ['danaans', 'argives', 'gods', 'others', 'trojans', 'bitten', 'squires', 'thracians', 'captains', 'magistrate']\n",
      "trojans ['danaans', 'argives', 'ground', 'achaeans', 'earth', 'scar', 'elders', 'satisfactory', 'suitors', 'tendons']\n",
      "achilles ['agamemnon', 'sundry', 'he', 'minerva', 'idomeneus', 'prodigy', 'hymning', 'menelaus', 'hector', 'ulysses']\n",
      "sea ['ground', 'blast', 'reign', 'nearer', 'sprinkle', 'foe', 'manes', 'happening', 'trench', 'blood']\n",
      "helen ['salamis', 'flit', 'ormenus', 'gadding', 'respite', 'quoit', 'nausicaa', 'rudders', 'divine', 'hey']\n",
      "ship ['mainland', 'bow', 'bottom', 'pyre', 'eagerness', 'veils', 'splendours', 'hoggets', 'fulness', 'offing']\n",
      "her ['his', 'your', 'sorts', 'dish', 'hoping', 'prayed', 'toppling', 'check', 'woke', 'olenus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:19<01:17, 19.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fight ['beginning', 'flinching', 'look', 'truce', 'wait', 'shouted', 'blazing', 'return', 'ground', 'bear']\n",
      "he ['she', 'they', 'i', 'scylla', 'achilles', 'loath', 'violet', 'nausicaa', 'scare', 'phemius']\n",
      "she ['he', 'ulysses', 'nausicaa', 'they', 'andromache', 'telemachus', 'angrily', 'severe', 'iris', 'i']\n",
      "ulysses ['telemachus', 'she', 'menelaus', 'penelope', 'achilles', 'eumaeus', 'euryclea', 'nausicaa', 'circe', 'ino']\n",
      "penelope ['ulysses', 'chirrup', 'fro', 'circe', 'beauty', 'telemachus', 'eyesight', 'idaeus', 'theoclymenus', 'storms']\n",
      "achaeans ['danaans', 'argives', 'trojans', 'immortals', 'gods', 'hills', 'others', 'thracians', 'phaeacians', 'lycians']\n",
      "trojans ['danaans', 'achaeans', 'argives', 'myrmidons', 'immortals', 'hills', 'tendons', 'egyptians', 'suitors', 'ghosts']\n",
      "achilles ['idomeneus', 'agamemnon', 'hector', 'ajax', 'melanthus', 'ulysses', 'patroclus', 'sundry', 'pisander', 'unplundered']\n",
      "sea ['foe', 'plain', 'blast', 'seas', 'bottom', 'sprinkle', 'trench', 'blood', 'seashore', 'town']\n",
      "helen ['nausicaa', 'hector', 'eagles', 'addition', 'paris', 'alexandrus', 'privately', 'salamis', 'rudders', 'pisander']\n",
      "ship ['bow', 'packing', 'herdsman', 'road', 'nape', 'noise', 'veils', 'bulwarks', 'tools', 'bath']\n",
      "her ['your', 'his', 'capaneus', 'sidon', 'woke', 'ctimene', 'wrangle', 'concert', 'salamis', 'deities']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:39<00:58, 19.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fight ['flinching', 'remain', 'shouted', 'wait', 'beginning', 'earth', 'truce', 'cower', 'whomsoever', 'satisfy']\n",
      "he ['she', 'they', 'achilles', 'i', 'scylla', 'we', 'adrestus', 'watchman', 'phemius', 'scare']\n",
      "she ['he', 'they', 'ulysses', 'nausicaa', 'i', 'privately', 'melantho', 'penelope', 'telemachus', 'andromache']\n",
      "ulysses ['telemachus', 'achilles', 'menelaus', 'eumaeus', 'penelope', 'antinous', 'privately', 'circe', 'nausicaa', 'theoclymenus']\n",
      "penelope ['circe', 'ulysses', 'idaeus', 'fro', 'dolius', 'chirrup', 'achilles', 'theoclymenus', 'pisistratus', 'proserpine']\n",
      "achaeans ['danaans', 'trojans', 'argives', 'immortals', 'lycians', 'gods', 'heralds', 'others', 'phereclus', 'hills']\n",
      "trojans ['danaans', 'achaeans', 'argives', 'myrmidons', 'immortals', 'others', 'fight', 'egyptians', 'lycians', 'phaeacians']\n",
      "achilles ['idomeneus', 'hector', 'agamemnon', 'pisander', 'ajax', 'melanthus', 'menelaus', 'ulysses', 'diomed', 'patroclus']\n",
      "sea ['bottom', 'seas', 'beck', 'seashore', 'steam', 'couches', 'daybreak', 'tug', 'linen', 'foe']\n",
      "helen ['nausicaa', 'pisander', 'barking', 'hector', 'heeding', 'leucothea', 'unrighteously', 'juno', 'privately', 'lycon']\n",
      "ship ['tools', 'bow', 'belly', 'breast', 'packing', 'nape', 'road', 'bath', 'herdsman', 'utmost']\n",
      "her ['his', 'deities', 'your', 'blithe', 'sidon', 'concert', 'their', 'hers', 'capaneus', 'wrangle']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:58<00:39, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fight ['remain', 'flinching', 'trojans', 'beginning', 'overreach', 'achaeans', 'wait', 'shouted', 'kindle', 'rout']\n",
      "he ['she', 'they', 'scylla', 'achilles', 'i', 'adrestus', 'salvation', 'we', 'watchman', 'euryalus']\n",
      "she ['he', 'they', 'privately', 'ulysses', 'nausicaa', 'juno', 'i', 'melanthius', 'penelope', 'melantho']\n",
      "ulysses ['telemachus', 'eumaeus', 'privately', 'nausicaa', 'circe', 'menelaus', 'achilles', 'bark', 'penelope', 'antinous']\n",
      "penelope ['circe', 'ulysses', 'dolius', 'proserpine', 'pisistratus', 'nausicaa', 'achilles', 'fro', 'chirrup', 'she']\n",
      "achaeans ['danaans', 'trojans', 'argives', 'immortals', 'lycians', 'gods', 'phereclus', 'heralds', 'hills', 'tables']\n",
      "trojans ['danaans', 'argives', 'achaeans', 'myrmidons', 'hills', 'immortals', 'others', 'suitors', 'phaecians', 'phaeacians']\n",
      "achilles ['hector', 'idomeneus', 'agamemnon', 'ajax', 'pisander', 'ulysses', 'patroclus', 'diomed', 'melanthus', 'antilochus']\n",
      "sea ['seas', 'bottom', 'beck', 'daybreak', 'tug', 'town', 'steam', 'seashore', 'rafters', 'phaethusa']\n",
      "helen ['barking', 'pisander', 'laodamas', 'leucothea', 'hearth', 'nausicaa', 'theano', 'ctesippus', 'penelope', 'frankincense']\n",
      "ship ['tools', 'bow', 'nape', 'belly', 'tent', 'breast', 'utmost', 'nigh', 'stick', 'bed']\n",
      "her ['his', 'your', 'sidon', 'blithe', 'capaneus', 'concert', 'their', 'hers', 'my', 'deities']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:18<00:19, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fight ['remain', 'bathe', 'overreach', 'return', 'wait', 'expound', 'insure', 'achaeans', 'stew', 'rout']\n",
      "he ['she', 'achilles', 'they', 'i', 'scylla', 'we', 'stoutly', 'vassal', 'salvation', 'watchman']\n",
      "she ['he', 'they', 'i', 'privately', 'ulysses', 'scylla', 'nausicaa', 'watchman', 'achilles', 'ino']\n",
      "ulysses ['telemachus', 'circe', 'menelaus', 'achilles', 'nausicaa', 'eumaeus', 'dione', 'penelope', 'calypso', 'antinous']\n",
      "penelope ['circe', 'chirrup', 'ulysses', 'proserpine', 'pisistratus', 'juno', 'dolius', 'achilles', 'telemachus', 'mentor']\n",
      "achaeans ['danaans', 'trojans', 'argives', 'lycians', 'immortals', 'others', 'phereclus', 'gods', 'phaecians', 'heralds']\n",
      "trojans ['danaans', 'achaeans', 'argives', 'myrmidons', 'others', 'hills', 'phaecians', 'phaeacians', 'immortals', 'suitors']\n",
      "achilles ['hector', 'agamemnon', 'idomeneus', 'he', 'menelaus', 'ajax', 'ulysses', 'patroclus', 'antilochus', 'aegisthus']\n",
      "sea ['seas', 'bottom', 'daybreak', 'beck', 'town', 'seashore', 'rhytium', 'tug', 'rafters', 'fertile']\n",
      "helen ['barking', 'laodamas', 'pisander', 'theano', 'ctesippus', 'themis', 'nausicaa', 'penelope', 'hearth', 'eurymedon']\n",
      "ship ['tools', 'tent', 'nape', 'bed', 'breast', 'utmost', 'stick', 'bow', 'chariot', 'cup']\n",
      "her ['your', 'his', 'blithe', 'concert', 'sidon', 'my', 'their', 'thy', 'capaneus', 'alike']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:40<00:00, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fight ['remain', 'bathe', 'rout', 'wait', 'overreach', 'stew', 'decide', 'expound', 'achaeans', 'trojans']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "VAL = False\n",
    "if VAL:\n",
    "    train_loss_history, train_acc_history, val_loss_history, val_acc_history = train_val_loop()\n",
    "else:\n",
    "    train_loss_history, train_acc_history = train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_acc_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_acc_history) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, train_acc_history, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbo\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, val_acc_history, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrx\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining and validation accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_acc_history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(train_acc_history) + 1)\n",
    "plt.plot(epochs, train_acc_history, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc_history, 'rx', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracies')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_loss_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_loss_history) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, train_loss_history, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbo\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, val_loss_history, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrx\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining and validation losses\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_loss_history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(train_loss_history) + 1)\n",
    "plt.plot(epochs, train_loss_history, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_history, 'rx', label='Validation loss')\n",
    "plt.title('Training and validation losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'cbow_dickens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3609,  0.3096, -0.2217,  ...,  1.2700, -0.4037, -0.5127],\n",
       "        [-0.1245, -3.1342, -1.5394,  ...,  2.0359,  0.6421,  0.4744],\n",
       "        [ 0.2404,  2.2039, -1.3967,  ...,  0.9678,  4.0001,  0.4083],\n",
       "        ...,\n",
       "        [-0.2823,  1.6095, -0.0814,  ..., -0.9071,  0.5590,  0.0990],\n",
       "        [ 0.4916,  0.7561,  0.3830,  ...,  2.1038, -0.4286,  0.9438],\n",
       "        [ 0.2610,  1.7445,  0.8745,  ..., -0.7903, -1.0701,  0.2558]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3609,  0.3096, -0.2217,  ...,  1.2700, -0.4037, -0.5127],\n",
       "        [-0.1245, -3.1342, -1.5394,  ...,  2.0359,  0.6421,  0.4744],\n",
       "        [ 0.2404,  2.2039, -1.3967,  ...,  0.9678,  4.0001,  0.4083],\n",
       "        ...,\n",
       "        [-0.2823,  1.6095, -0.0814,  ..., -0.9071,  0.5590,  0.0990],\n",
       "        [ 0.4916,  0.7561,  0.3830,  ...,  2.1038, -0.4286,  0.9438],\n",
       "        [ 0.2610,  1.7445,  0.8745,  ..., -0.7903, -1.0701,  0.2558]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9768, 50])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    model[0].weight.detach().numpy(), \n",
    "    index=[idx2word[i] for i in range(len(idx2word))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.360905</td>\n",
       "      <td>0.309618</td>\n",
       "      <td>-0.221730</td>\n",
       "      <td>0.102910</td>\n",
       "      <td>1.233467</td>\n",
       "      <td>-0.619417</td>\n",
       "      <td>0.354415</td>\n",
       "      <td>-0.909990</td>\n",
       "      <td>1.558370</td>\n",
       "      <td>-1.557356</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.415021</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.795877</td>\n",
       "      <td>-0.911840</td>\n",
       "      <td>0.450392</td>\n",
       "      <td>-1.747212</td>\n",
       "      <td>-0.029444</td>\n",
       "      <td>1.269959</td>\n",
       "      <td>-0.403748</td>\n",
       "      <td>-0.512697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abantes</th>\n",
       "      <td>-0.124511</td>\n",
       "      <td>-3.134156</td>\n",
       "      <td>-1.539351</td>\n",
       "      <td>-2.213443</td>\n",
       "      <td>-0.528597</td>\n",
       "      <td>0.878430</td>\n",
       "      <td>2.515538</td>\n",
       "      <td>1.315774</td>\n",
       "      <td>0.684114</td>\n",
       "      <td>0.416358</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.626820</td>\n",
       "      <td>-0.523154</td>\n",
       "      <td>1.468027</td>\n",
       "      <td>-0.373985</td>\n",
       "      <td>-2.501289</td>\n",
       "      <td>-2.501449</td>\n",
       "      <td>-0.455023</td>\n",
       "      <td>2.035898</td>\n",
       "      <td>0.642090</td>\n",
       "      <td>0.474413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abarbarea</th>\n",
       "      <td>0.240392</td>\n",
       "      <td>2.203930</td>\n",
       "      <td>-1.396699</td>\n",
       "      <td>2.816573</td>\n",
       "      <td>-1.141785</td>\n",
       "      <td>-0.395663</td>\n",
       "      <td>0.210799</td>\n",
       "      <td>-0.032763</td>\n",
       "      <td>2.466990</td>\n",
       "      <td>0.214982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.293705</td>\n",
       "      <td>-0.132710</td>\n",
       "      <td>0.230625</td>\n",
       "      <td>0.253468</td>\n",
       "      <td>-0.001569</td>\n",
       "      <td>-0.746037</td>\n",
       "      <td>-1.209782</td>\n",
       "      <td>0.967773</td>\n",
       "      <td>4.000123</td>\n",
       "      <td>0.408297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abas</th>\n",
       "      <td>-0.249593</td>\n",
       "      <td>-0.809223</td>\n",
       "      <td>1.430726</td>\n",
       "      <td>0.508630</td>\n",
       "      <td>-2.297618</td>\n",
       "      <td>-4.433473</td>\n",
       "      <td>0.266501</td>\n",
       "      <td>0.375968</td>\n",
       "      <td>0.536330</td>\n",
       "      <td>-1.024946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402080</td>\n",
       "      <td>0.275511</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>0.480708</td>\n",
       "      <td>0.152093</td>\n",
       "      <td>1.406158</td>\n",
       "      <td>0.244994</td>\n",
       "      <td>0.317736</td>\n",
       "      <td>-0.834975</td>\n",
       "      <td>-1.185916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abate</th>\n",
       "      <td>-1.768644</td>\n",
       "      <td>0.180203</td>\n",
       "      <td>-2.018601</td>\n",
       "      <td>0.111741</td>\n",
       "      <td>-1.087932</td>\n",
       "      <td>-0.070355</td>\n",
       "      <td>-0.942351</td>\n",
       "      <td>0.241398</td>\n",
       "      <td>0.823600</td>\n",
       "      <td>-1.108382</td>\n",
       "      <td>...</td>\n",
       "      <td>2.055421</td>\n",
       "      <td>-1.964629</td>\n",
       "      <td>1.020981</td>\n",
       "      <td>-2.229958</td>\n",
       "      <td>0.945172</td>\n",
       "      <td>-3.684698</td>\n",
       "      <td>1.405313</td>\n",
       "      <td>-0.119008</td>\n",
       "      <td>2.511402</td>\n",
       "      <td>-0.371257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeal</th>\n",
       "      <td>2.149769</td>\n",
       "      <td>0.298278</td>\n",
       "      <td>-2.283236</td>\n",
       "      <td>-3.378420</td>\n",
       "      <td>-0.715643</td>\n",
       "      <td>-2.243176</td>\n",
       "      <td>-1.766015</td>\n",
       "      <td>-0.477300</td>\n",
       "      <td>-1.198361</td>\n",
       "      <td>-0.898667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.032845</td>\n",
       "      <td>1.353052</td>\n",
       "      <td>-1.097090</td>\n",
       "      <td>-1.024076</td>\n",
       "      <td>1.476706</td>\n",
       "      <td>0.014351</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>2.088631</td>\n",
       "      <td>1.900561</td>\n",
       "      <td>-1.801711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zelea</th>\n",
       "      <td>-1.139118</td>\n",
       "      <td>0.382446</td>\n",
       "      <td>1.378164</td>\n",
       "      <td>0.510787</td>\n",
       "      <td>-0.739776</td>\n",
       "      <td>0.012274</td>\n",
       "      <td>0.704571</td>\n",
       "      <td>0.661585</td>\n",
       "      <td>2.927667</td>\n",
       "      <td>-2.147072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490746</td>\n",
       "      <td>0.946405</td>\n",
       "      <td>1.114837</td>\n",
       "      <td>-1.756375</td>\n",
       "      <td>2.087635</td>\n",
       "      <td>-1.895787</td>\n",
       "      <td>-0.636752</td>\n",
       "      <td>1.367887</td>\n",
       "      <td>0.891487</td>\n",
       "      <td>3.895625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyrus</th>\n",
       "      <td>-0.282296</td>\n",
       "      <td>1.609492</td>\n",
       "      <td>-0.081373</td>\n",
       "      <td>2.036999</td>\n",
       "      <td>0.416994</td>\n",
       "      <td>-0.089048</td>\n",
       "      <td>1.369559</td>\n",
       "      <td>-0.564614</td>\n",
       "      <td>-0.549927</td>\n",
       "      <td>-0.140541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589239</td>\n",
       "      <td>1.434375</td>\n",
       "      <td>1.906418</td>\n",
       "      <td>0.617077</td>\n",
       "      <td>-2.534457</td>\n",
       "      <td>-1.210817</td>\n",
       "      <td>1.392520</td>\n",
       "      <td>-0.907114</td>\n",
       "      <td>0.559045</td>\n",
       "      <td>0.098993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zethus</th>\n",
       "      <td>0.491612</td>\n",
       "      <td>0.756094</td>\n",
       "      <td>0.382969</td>\n",
       "      <td>-0.307649</td>\n",
       "      <td>-3.048690</td>\n",
       "      <td>-1.725932</td>\n",
       "      <td>2.698186</td>\n",
       "      <td>0.808782</td>\n",
       "      <td>0.673495</td>\n",
       "      <td>1.091117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600674</td>\n",
       "      <td>1.648937</td>\n",
       "      <td>1.133444</td>\n",
       "      <td>0.776669</td>\n",
       "      <td>0.174629</td>\n",
       "      <td>-2.442813</td>\n",
       "      <td>0.469771</td>\n",
       "      <td>2.103827</td>\n",
       "      <td>-0.428551</td>\n",
       "      <td>0.943839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeus</th>\n",
       "      <td>0.261014</td>\n",
       "      <td>1.744450</td>\n",
       "      <td>0.874480</td>\n",
       "      <td>1.967373</td>\n",
       "      <td>-0.711970</td>\n",
       "      <td>-0.436667</td>\n",
       "      <td>-0.540426</td>\n",
       "      <td>2.687812</td>\n",
       "      <td>1.866261</td>\n",
       "      <td>-0.650397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840549</td>\n",
       "      <td>2.119237</td>\n",
       "      <td>-0.990102</td>\n",
       "      <td>2.677027</td>\n",
       "      <td>-0.786067</td>\n",
       "      <td>-0.173755</td>\n",
       "      <td>-0.636329</td>\n",
       "      <td>-0.790308</td>\n",
       "      <td>-1.070071</td>\n",
       "      <td>0.255768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9768 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5   \\\n",
       "a          0.360905  0.309618 -0.221730  0.102910  1.233467 -0.619417   \n",
       "abantes   -0.124511 -3.134156 -1.539351 -2.213443 -0.528597  0.878430   \n",
       "abarbarea  0.240392  2.203930 -1.396699  2.816573 -1.141785 -0.395663   \n",
       "abas      -0.249593 -0.809223  1.430726  0.508630 -2.297618 -4.433473   \n",
       "abate     -1.768644  0.180203 -2.018601  0.111741 -1.087932 -0.070355   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "zeal       2.149769  0.298278 -2.283236 -3.378420 -0.715643 -2.243176   \n",
       "zelea     -1.139118  0.382446  1.378164  0.510787 -0.739776  0.012274   \n",
       "zephyrus  -0.282296  1.609492 -0.081373  2.036999  0.416994 -0.089048   \n",
       "zethus     0.491612  0.756094  0.382969 -0.307649 -3.048690 -1.725932   \n",
       "zeus       0.261014  1.744450  0.874480  1.967373 -0.711970 -0.436667   \n",
       "\n",
       "                 6         7         8         9   ...        40        41  \\\n",
       "a          0.354415 -0.909990  1.558370 -1.557356  ... -1.415021  0.931507   \n",
       "abantes    2.515538  1.315774  0.684114  0.416358  ... -2.626820 -0.523154   \n",
       "abarbarea  0.210799 -0.032763  2.466990  0.214982  ... -0.293705 -0.132710   \n",
       "abas       0.266501  0.375968  0.536330 -1.024946  ... -0.402080  0.275511   \n",
       "abate     -0.942351  0.241398  0.823600 -1.108382  ...  2.055421 -1.964629   \n",
       "...             ...       ...       ...       ...  ...       ...       ...   \n",
       "zeal      -1.766015 -0.477300 -1.198361 -0.898667  ...  1.032845  1.353052   \n",
       "zelea      0.704571  0.661585  2.927667 -2.147072  ...  0.490746  0.946405   \n",
       "zephyrus   1.369559 -0.564614 -0.549927 -0.140541  ...  0.589239  1.434375   \n",
       "zethus     2.698186  0.808782  0.673495  1.091117  ...  0.600674  1.648937   \n",
       "zeus      -0.540426  2.687812  1.866261 -0.650397  ...  0.840549  2.119237   \n",
       "\n",
       "                 42        43        44        45        46        47  \\\n",
       "a          0.795877 -0.911840  0.450392 -1.747212 -0.029444  1.269959   \n",
       "abantes    1.468027 -0.373985 -2.501289 -2.501449 -0.455023  2.035898   \n",
       "abarbarea  0.230625  0.253468 -0.001569 -0.746037 -1.209782  0.967773   \n",
       "abas       1.027664  0.480708  0.152093  1.406158  0.244994  0.317736   \n",
       "abate      1.020981 -2.229958  0.945172 -3.684698  1.405313 -0.119008   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "zeal      -1.097090 -1.024076  1.476706  0.014351  0.686022  2.088631   \n",
       "zelea      1.114837 -1.756375  2.087635 -1.895787 -0.636752  1.367887   \n",
       "zephyrus   1.906418  0.617077 -2.534457 -1.210817  1.392520 -0.907114   \n",
       "zethus     1.133444  0.776669  0.174629 -2.442813  0.469771  2.103827   \n",
       "zeus      -0.990102  2.677027 -0.786067 -0.173755 -0.636329 -0.790308   \n",
       "\n",
       "                 48        49  \n",
       "a         -0.403748 -0.512697  \n",
       "abantes    0.642090  0.474413  \n",
       "abarbarea  4.000123  0.408297  \n",
       "abas      -0.834975 -1.185916  \n",
       "abate      2.511402 -0.371257  \n",
       "...             ...       ...  \n",
       "zeal       1.900561 -1.801711  \n",
       "zelea      0.891487  3.895625  \n",
       "zephyrus   0.559045  0.098993  \n",
       "zethus    -0.428551  0.943839  \n",
       "zeus      -1.070071  0.255768  \n",
       "\n",
       "[9768 rows x 50 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBOW_GEN_VECTOR_FILE = 'cbow_pt_dickent.txt'\n",
    "# df.to_csv(CBOW_GEN_VECTOR_FILE, sep=' ', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he ['she', 'achilles', 'they']\n",
      "she ['he', 'they', 'i']\n",
      "ulysses ['telemachus', 'circe', 'menelaus']\n",
      "penelope ['circe', 'chirrup', 'ulysses']\n",
      "achaeans ['danaans', 'trojans', 'argives']\n",
      "trojans ['danaans', 'achaeans', 'argives']\n",
      "achilles ['hector', 'agamemnon', 'idomeneus']\n",
      "sea ['seas', 'bottom', 'daybreak']\n",
      "helen ['barking', 'laodamas', 'pisander']\n",
      "ship ['tools', 'tent', 'nape']\n",
      "her ['your', 'his', 'blithe']\n",
      "fight ['remain', 'bathe', 'rout']\n"
     ]
    }
   ],
   "source": [
    "sim_test_words(test_words, word2idx, model, N=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NAdam 0.025 64\n",
    "he ['she', 'they', 'i', 'alegenor', 'we', 'shoo', 'achilles', 'antilochus', 'xaging', 'it']\n",
    "she ['he', 'they', 'nausicaa', 'i', 'we', 'juno', 'oeneus', 'raven', 'alcestis', 'minerva']\n",
    "ulysses ['telemachus', 'alexandrus', 'melanthius', 'peleus', 'antinous', 'diomed', 'eumaeus', 'angrily', 'rag', 'belonged']\n",
    "penelope ['telemachus', 'juno', 'nausicaa', 'arete', 'melaneus', 'noemon', 'cisseus', 'jove', 'august', 'arybas']\n",
    "achaeans ['danaans', 'argives', 'trojans', 'crowning', 'suitors', 'bench', 'lycians', 'ephyri', 'precincts', 'gods']\n",
    "trojans ['danaans', 'achaeans', 'argives', 'suitors', 'others', 'packing', 'centaurs', 'rout', 'cephallenians', 'ies']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NAdam 0.025 32\n",
    "he ['she', 'achilles', 'they', 'i', 'ulysses', 'we', 'minerva', 'alision', 'papa', 'euryalus']\n",
    "she ['he', 'they', 'i', 'euryalus', 'we', 'juno', 'ulysses', 'euryclea', 'nausicaa', 'minerva']\n",
    "ulysses ['telemachus', 'achilles', 'agamemnon', 'antinous', 'nestor', 'juno', 'menelaus', 'neptune', 'alcinous', 'dreamland']\n",
    "penelope ['juno', 'telemachus', 'ulysses', 'numberless', 'dress', 'eilesium', 'alcinous', 'pisistratus', 'apollo', 'prayer']\n",
    "achaeans ['danaans', 'argives', 'trojans', 'others', 'suitors', 'gods', 'myrmidons', 'chiefest', 'rest', 'locrians']\n",
    "trojans ['achaeans', 'argives', 'danaans', 'maker', 'myrmidons', 'pylaeus', 'ephyri', 'mainland', 'lycians', 'suitors']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NAdam 0.025\n",
    "he ['she', 'they', 'i', 'teucer', 'we', 'epeigeus', 'overturned', 'arnaeus', 'stoutly', 'alision']\n",
    "she ['he', 'they', 'happening', 'diana', 'heartily', 'shrouds', 'ulysses', 'augury', 'earnings', 'circe']\n",
    "ulysses ['telemachus', 'achilles', 'agamemnon', 'peleus', 'bark', 'euryalus', 'euaemon', 'retreat', 'melantho', 'melanthius']\n",
    "penelope ['telemachus', 'thersites', 'content', 'heedless', 'farewell', 'august', 'eumaeus', 'arne', 'trifles', 'juno']\n",
    "achaeans ['argives', 'juice', 'chalk', 'mainstays', 'lycians', 'trojans', 'pervaded', 'danaans', 'islands', 'lelegae']\n",
    "trojans ['argives', 'seashore', 'crowning', 'danaans', 'curetes', 'achaeans', 'tip', 'unflinching', 'darts', 'ajaxes']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "he ['she', 'they', 'i', 'we', 'pillows', 'achilles', 'chiron', 'cases', 'vassal', 'thrives']\n",
    "she ['he', 'they', 'papa', 'i', 'dardanus', 'we', 'shrouds', 'penelope', 'pillows', 'vassal']\n",
    "ulysses ['antinous', 'diomed', 'menelaus', 'peleus', 'telemachus', 'hector', 'amphiclus', 'sisyphus', 'schedius', 'meriones']\n",
    "penelope ['telemachus', 'venus', 'reflected', 'ointment', 'aspen', 'ivory', 'autolycus', 'nereus', 'jove', 'wheelwright']\n",
    "achaeans ['danaans', 'phoceans', 'games', 'argives', 'phalanxes', 'heralds', 'mainstays', 'clattering', 'fulness', 'trojans']\n",
    "trojans ['danaans', 'thracians', 'ringleaders', 'achaeans', 'argives', 'cythereans', 'tendons', 'strangers', 'platform', 'stepmother']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBOW_GEN_VECTOR_FILE = 'cbow_pt_dickent.txt'\n",
    "# df.to_csv(CBOW_GEN_VECTOR_FILE, sep=' ', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RMS 10 0.1 1024\n",
    "he ['she', 'they', 'i', 'nicholas', 'it', 'bullyers', 'reducible', 'we', 'oliver', 'superstitiously']\n",
    "she ['he', 'they', 'i', 'florence', 'superstitiously', 'nicholas', 'it', 'topographical', 'we', 'bullyers']\n",
    "paris ['london', 'switzerland', 'newgate', 'default', 'aeronautics', 'italy', 'yorkshire', 'earwigs', 'town', 'rome']\n",
    "london ['paris', 'india', 'england', 'town', 'harley', 'chertsey', 'highgate', 'ipswich', 'greta', 'blackfriars']\n",
    "table ['desk', 'chimneypiece', 'sideboard', 'room', 'floor', 'tables', 'sofa', 'stove', 'beach', 'settee']\n",
    "rare ['defective', 'gratuitous', 'capital', 'perversion', 'curator', 'chatty', 'hymn', 'common', 'dense', 'funny']\n",
    "monday ['thursday', 'friday', 'sunday', 'wednesday', 'accounts', 'verged', 'occasions', 'heaths', 'studies', 'morrow']\n",
    "sunday ['wednesday', 'friday', 'saturday', 'morning', 'day', 'week', 'monday', 'dialect', 'experimented', 'evenings']\n",
    "man ['gentleman', 'woman', 'person', 'boy', 'lady', 'creature', 'jew', 'girl', 'child', 'dog']\n",
    "woman ['man', 'lady', 'girl', 'gentleman', 'child', 'creature', 'boy', 'person', 'jew', 'cherub']\n",
    "king ['calf', 'devil', 'saracen', 'jambs', 'sortin', 'manufacture', 'clank', 'tribune', 'mob', 'pilot']\n",
    "queen ['speaker', 'leech', 'hungering', 'shawled', 'needle', 'miracles', 'servants', 'mississes', 'twin', 'straggling']\n",
    "boy ['girl', 'child', 'creature', 'man', 'jew', 'gentleman', 'woman', 'person', 'sexton', 'dwarf']\n",
    "girl ['child', 'woman', 'boy', 'creature', 'gentleman', 'lady', 'man', 'widow', 'jew', 'dwarf']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RMS. 0.01, 512, 10\n",
    "he ['she', 'erylaus', 'we', 'they', 'vassal', 'i', 'thirsting', 'alision', 'aegae', 'syra']\n",
    "she ['he', 'they', 'joy', 'complexion', 'telemachus', 'pillaged', 'penelope', 'fondly', 'anywhere', 'chalcis']\n",
    "ulysses ['antinous', 'telemachus', 'euryalus', 'diomed', 'pisistratus', 'capaneus', 'ismarus', 'argue', 'aesculapius', 'axylus']\n",
    "penelope ['neptune', 'piraeus', 'nisus', 'pisistratus', 'arete', 'circe', 'achilles', 'echeneus', 'such', 'weave']\n",
    "achaeans ['danaans', 'argives', 'gods', 'others', 'trojans', 'resisted', 'givers', 'habit', 'lycians', 'seashore']\n",
    "trojans ['danaans', 'thesprotians', 'locrians', 'storming', 'achaeans', 'swineherd', 'rushes', 'issued', 'hazard', 'rangers']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NAdam 0.025 64\n",
    "he ['she', 'they', 'i', 'it', 'we', 'paul', 'woefully', 'nobody', 'everybody', 'kit']\n",
    "she ['he', 'they', 'i', 'florence', 'we', 'paul', 'caddy', 'it', 'bella', 'rosa']\n",
    "paris ['england', 'italy', 'town', 'contravention', 'london', 'columbus', 'switzerland', 'coketown', 'oozy', 'scots']\n",
    "london ['england', 'saleable', 'town', 'saltatory', 'france', 'paris', 'ina', 'skate', 'reconsidering', 'pestilential']\n",
    "table ['floor', 'room', 'inkstand', 'fender', 'tables', 'hob', 'spot', 'portico', 'beach', 'pandean']\n",
    "rare ['stupendous', 'apposite', 'drone', 'simple', 'practical', 'rotatory', 'navigator', 'somnolent', 'rumination', 'cumber']\n",
    "monday ['sunday', 'noon', 'admissible', 'gunwales', 'wisited', 'brighton', 'farder', 'eulogy', 'forefoot', 'unhindered']\n",
    "sunday ['monday', 'friday', 'ablutions', 'failure', 'wednesday', 'seeker', 'broomstick', 'forefoot', 'guercino', 'trial']\n",
    "man ['gentleman', 'woman', 'person', 'lady', 'boy', 'girl', 'creature', 'chap', 'lad', 'surgeon']\n",
    "woman ['man', 'gentleman', 'creature', 'girl', 'lady', 'child', 'person', 'boy', 'fellow', 'trick']\n",
    "king ['nests', 'mayor', 'shoemaker', 'heeling', 'originals', 'perfumer', 'darnay', 'cowpock', 'sounders', 'generically']\n",
    "queen ['gals', 'chancery', 'fellow', 'hanover', 'marine', 'summersets', 'lambs', 'chastity', 'rotund', 'circular']\n",
    "boy ['child', 'girl', 'man', 'schoolmaster', 'jew', 'woman', 'constable', 'creature', 'gentleman', 'dog']\n",
    "girl ['child', 'woman', 'creature', 'schoolmaster', 'boy', 'lady', 'man', 'gentleman', 'jew', 'surgeon']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RMS 1024 0.1 10\n",
    "he ['she', 'they', 'sheepskin', 'coiranus', 'i', 'heeding', 'papa', 'alesium', 'device', 'keener']\n",
    "she ['he', 'stars', 'juno', 'emathia', 'nausicaa', 'saffron', 'requital', 'persisted', 'maids', 'unwed']\n",
    "ulysses ['telemachus', 'nightfall', 'levers', 'piraeus', 'peleus', 'lagging', 'perseus', 'alexandrus', 'achilles', 'melantho']\n",
    "penelope ['circe', 'antinous', 'nightfall', 'autonoe', 'augurs', 'helen', 'passing', 'dress', 'telemachus', 'precipice']\n",
    "achaeans ['argives', 'trojans', 'danaans', 'crowning', 'contrary', 'cowards', 'sintians', 'lapithae', 'erymas', 'renewed']\n",
    "trojans ['achaeans', 'meonians', 'storming', 'argives', 'danaans', 'myrmidons', 'epeans', 'acropolis', 'phrygians', 'tyres']\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
